import pandas as pd
import numpy as np
from scipy.stats import ks_2samp
import logging
import os

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def check_data_drift(baseline_path, production_path, alpha=0.05):
    """
    Compares baseline (train) data vs. production (test) data using K-S Test.
    """
    if not os.path.exists(baseline_path) or not os.path.exists(production_path):
        logger.error("‚ùå Data files not found. Run the pipeline first!")
        return

    # 1. Load Data
    logger.info(f"üìâ Loading baseline: {baseline_path}")
    df_baseline = pd.read_csv(baseline_path)
    
    logger.info(f"üìà Loading production (proxy): {production_path}")
    df_prod = pd.read_csv(production_path)

    # 2. Identify Numeric Features to Monitor
    # We exclude targets and non-numeric columns
    exclude = ['y_class', 'QuantitySold', 'quantity_class', 'Date', 'ItemCode', 'BranchID', 'InvoiceNumber']
    features = [c for c in df_baseline.columns if c not in exclude and np.issubdtype(df_baseline[c].dtype, np.number)]
    
    logger.info(f"üîç Monitoring {len(features)} features for drift...")

    drift_detected = False
    
    # 3. Perform Kolmogorov-Smirnov Test
    for feature in features:
        # Get clean arrays (drop NaNs just in case)
        data_b = df_baseline[feature].dropna()
        data_p = df_prod[feature].dropna()
        
        if len(data_b) == 0 or len(data_p) == 0:
            continue

        stat, p_value = ks_2samp(data_b, data_p)
        
        if p_value < alpha:
            logger.warning(f"‚ö†Ô∏è Drift Detected in '{feature}' (p-value: {p_value:.4f})")
            drift_detected = True
        else:
            logger.info(f"‚úÖ Stable: '{feature}' (p-value: {p_value:.4f})")

    if not drift_detected:
        logger.info("üéâ No significant data drift detected across the dataset.")
    else:
        logger.warning("‚ö†Ô∏è Data drift detected! Model retraining might be required.")

if __name__ == "__main__":
    # Paths to the real data generated by your pipeline
    TRAIN_PATH = "data/processed/train.csv"
    TEST_PATH = "data/processed/test.csv"
    
    check_data_drift(TRAIN_PATH, TEST_PATH)